<!DOCTYPE html>
<html>
<head>
	<title>Motion tracking</title>
</head>
<body>
	<h1>Motion tracking</h1>
	<img src="../images/image34.jpeg" alt="image34">
	<p>
	Head tracking is one big advantage the as-yet unreleased premium headsets have over the likes of Cardboard. But the big VR players are still working out motion tracking. When you look down with a VR headset on the first thing you want to do is see your hands in a virtual space.
	</p>
	<p>
	For a while, we've seen the Leap Motion accessory - which uses an infrared sensor to track hand movements - strapped to the front of Oculus dev kits. We've also tried a few experiments with Kinect 2 cameras tracking our flailing bodies. But now we have exciting input options from Oculus, Valve and Sony.
	</p>
	<p>
	Oculus Touch is a set of wireless controllers, designed to make you feel like you're using your own hands in VR. You grab each controller and use buttons, thumbsticks and triggers during VR games. So for instance, to shoot a gun you squeeze on the hand trigger. There is also a matrix of sensors on each controller to detect gestures such as pointing and waving.
	</p>
	<h2>Headset head-to-head: HTC Vive versus Oculus Rift</h2>
	<p>
	It's a pretty similar set-up to Valve's Lighthouse positional tracking system and HTC's controllers for its Vive headset. It involves two base stations around the room which sweep the area with lasers. These can detect the precise position of your head and both hands based on the timing of when they hit each photocell sensor on both the headset and around each handheld controller. Like Oculus Touch, these also feature physical buttons too and incredibly you can have two Lighthouse systems in the same space to track multiple users.
	</p>
	<p>
	Other input methods can include anything from hooking an Xbox controller or joystick up to your PC, voice controls, smart gloves and treadmills such as the Virtuix Omni, which allow you to simulate walking around a VR environment with clever in-game redirections.
	</p>
</body>
</html>